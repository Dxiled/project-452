{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mWF1dPonZKbR"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"d57LHlsgZVmp"},"source":["# Environment Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20397,"status":"ok","timestamp":1669514705919,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"},"user_tz":300},"id":"jZpEPDaUZUrf","outputId":"078af8a3-20ed-49e8-f893-65894f50c53a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Colab setup if on colab\n","try:\n","    from google.colab import drive\n","    mount_point = \"/content/gdrive\"\n","    drive.mount(mount_point)\n","except:\n","    mount_point = \"\"\n","\n","# data location\n","path = mount_point + \"/My Drive/CISC452/Project/enron2/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MR19BHPpa2Md"},"outputs":[],"source":["ham = os.scandir(path + 'ham')\n","spam = os.scandir(path + 'spam')\n","df = pd.DataFrame({'Text': [], 'IsSpam': []})\n","\n","for entry in ham:\n","    file_name = path + 'ham/' + entry.name\n","    f = open(file_name, mode='r', encoding='latin1')\n","    txt = f.read().lower()\n","    f.close()\n","\n","    df = df.append({'Text': txt, 'IsSpam': False}, ignore_index=True)\n","\n","for entry in spam:\n","    file_name = path + 'spam/' + entry.name\n","    f = open(file_name, mode='r', encoding='latin1')\n","    txt = f.read().lower()\n","    f.close()\n","\n","    df = df.append({'Text': txt, 'IsSpam': True}, ignore_index=True)\n","\n","df = df.sample(frac=1, random_state=20221122).reset_index(drop=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":148,"status":"ok","timestamp":1669415973280,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"},"user_tz":300},"id":"V3S206SsYz1g","outputId":"5be6919c-07d6-41d9-fe64-fafb63bae8d2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text  IsSpam\n","0  subject: wallstreet pulse\\ngood day to all bro...     1.0\n","1  subject: re : anita dupont resume\\noooopppss !...     0.0\n","2  subject: hiring aram at a vp level\\nrick ,\\ni ...     0.0\n","3  subject: seeking your partnership\\ndear partne...     1.0\n","4  subject: wharton tiger team agenda\\nfriends ,\\...     0.0"],"text/html":["\n","  <div id=\"df-2e81fecc-7534-49e0-86a3-e5301f205a8f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>IsSpam</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>subject: wallstreet pulse\\ngood day to all bro...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>subject: re : anita dupont resume\\noooopppss !...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>subject: hiring aram at a vp level\\nrick ,\\ni ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>subject: seeking your partnership\\ndear partne...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>subject: wharton tiger team agenda\\nfriends ,\\...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e81fecc-7534-49e0-86a3-e5301f205a8f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2e81fecc-7534-49e0-86a3-e5301f205a8f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2e81fecc-7534-49e0-86a3-e5301f205a8f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["df_train, df_test = train_test_split(df, test_size=0.2, random_state=20221122)\n","df_train.reset_index(drop=True, inplace=True)\n","df_test.reset_index(drop=True, inplace=True)\n","df_test.head()"]},{"cell_type":"markdown","metadata":{"id":"PVN365cyZAri"},"source":["# Tokenizers\n","\n","PyTorch default tokenizer tokenizes by full words. "]},{"cell_type":"code","source":["from torchtext.data import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","tokenizer = get_tokenizer(\"basic_english\")\n","\n","def build_vocabulary(dataframe):\n","    for text in dataframe['Text']:\n","        yield tokenizer(text)\n","\n","torch_vocab = build_vocab_from_iterator(build_vocabulary(df_train), min_freq=1, specials=[\"<UNK>\"])\n","\n","torch_vocab.set_default_index(torch_vocab[\"<UNK>\"])"],"metadata":{"id":"EIGvBN7VilY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(torch_vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8O5460qozbAQ","executionInfo":{"status":"ok","timestamp":1669415993701,"user_tz":300,"elapsed":117,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"f2c27e8b-1662-4412-eb5f-20283ccdaa52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["36274\n"]}]},{"cell_type":"code","source":["print(tokenizer(df_train['Text'][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDgHZ2nGzzEr","executionInfo":{"status":"ok","timestamp":1669415995740,"user_tz":300,"elapsed":130,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"68d46384-55c1-46b7-8e82-c02808e667c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['subject', 'template', 'for', 'pricing', 'the', 'right', 'of', 'first', 'refusal', 'shelley', 'and', 'chris', ',', 'i', 'have', 'set', 'up', 'a', 'template', 'for', 'pricing', 'rofrs', '.', 'the', 'rofr', 'is', 'priced', 'as', 'a', 'series', 'forward', 'start', 'options', '.', 'a', 'forward', 'start', 'option', 'gives', 'the', 'holder', 'the', 'right', 'to', 'exercise', 'the', 'option', 'but', 'the', 'strike', 'price', 'is', 'set', 'at', 'the', 'money', 'in', 'future', 'before', 'the', 'option', 'expiration', '.', 'the', 'feature', 'mimics', 'the', 'matching', 'the', 'best', 'bid', 'in', 'the', 'rofr', '.', 'the', 'underlying', 'for', 'the', 'option', 'is', 'the', 'best', 'bid', ',', 'which', 'should', 'be', 'closely', 'related', 'to', 'the', 'price', 'differential', 'between', 'the', 'two', 'hubs', 'that', 'the', 'pipeline', 'connects', '.', 'therefore', 'the', 'rofr', 'is', 'case', 'dependent', ',', 'as', 'vince', 'pointed', 'out', '.', 'the', 'volatility', 'can', 'be', 'estimated', 'from', 'the', 'best', 'bid', 'price', 'history', '.', 'with', 'these', 'inputs', 'we', 'can', 'estimate', 'the', 'value', 'of', 'rofr', '.', 'if', 'you', 'have', 'any', 'questions', 'concerning', 'the', 'model', 'please', 'feel', 'free', 'to', 'call', 'me', 'or', 'vince', '.', 'zimin', 'lu']\n"]}]},{"cell_type":"markdown","source":["My custom tokenizer uses byte-pair encoding to tokenize sub-words instead of full words by freqency. This allows the tokens to better represent meanings of similar words. For example, 'email' might be tokenized as a full word, but 'emailing' might be tokenized into email-ing. \n","\n","The benefit of this approach is that it vastly decreases the vocabulary size, and thus the dimensionality, of the input data (on this dataset, is method provides a vocabulary of between 1000 and 1100 unique tokens), while still preserving more information than a naive character-delimited tokenization method would provide. \n","\n","The drawback is that rare words such as names might be tokenized rather meaninglessly (for example, deathridge as de-a-thr-id-ge). \n","\n","The Tokenizer class takes two arguments - the max vocabulary size `vocab_size` and the minimum frequency for byte-pair tokenization `min_freq`. The training ends when either vocabulary size reaches `vocab_size`, or the most common byte-pair is less frequent than `min_freq`."],"metadata":{"id":"HzlAFlFWijmi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7p0Uz5nTZEhd"},"outputs":[],"source":["class Tokenizer(object):\n","    def __init__(self, vocab_size=2048, min_freq=500):\n","        if vocab_size < 1:\n","            self.vocab_size = 2048\n","        else:\n","            self.vocab_size = vocab_size\n","        self.min_freq = min_freq\n","        self.encoding = {}\n","        self.decoding = {}\n","        self.vocab = set()\n","    \n","    # Generate an encoding mapping from a dataset\n","    def learn(self, train):\n","        # Generate a corpus of words from the training set\n","        corpus = {}\n","        for i, row in train.iterrows():\n","            txt = row['Text'].replace('\\n', ' ')\n","            dat = txt.split(' ')\n","            # Adds each word to the corpus (around 33000 words in the enron2 set)\n","            for word in dat:\n","                # Append an End-Of-Word byte to each word. Choosing space to take advantage of existing preprocessing\n","                # This allows the tokenizer to distinguish between similar tokens \n","                # like the 'ed' in 'learned' and the 'ed' in 'education'\n","\n","                # Note: The dataset is too small for this to matter.\n","                # It actually results in lower-quality tokenization because it leaves pairs that would otherwise be common enough to compress.\n","                # Therefore, this step is abandoned.\n","                wordw = word # + ' '\n","\n","                if wordw in corpus.keys():\n","                    corpus[wordw] += 1\n","                else:\n","                    corpus[wordw] = 1\n","        \n","        print(\"Corpus size: \", len(corpus))\n","        # Populate the vocabulary with initial characters\n","        for word in corpus.keys():\n","            for ch in word:\n","                self.vocab.add(ch)\n","        \n","        unused_byte = 256  # the max ord of any char in the dataset is 254, so any char past 256 is unused\n","\n","        # Compress byte-pairs until the vocab size exceeds the allowed limit\n","        while len(self.vocab) < self.vocab_size:\n","            # Counts the occurences of all byte-pairs in the corpus\n","            byte_pairs = {}\n","            for word in corpus.keys():\n","                for i in range(len(word) - 1):\n","                    pair = word[i:i+2]\n","                    if pair in byte_pairs.keys():\n","                        byte_pairs[pair] += corpus[word]\n","                    else:\n","                        byte_pairs[pair] = corpus[word]\n","            \n","            # Gets the most frequent byte pair\n","            most_frequent = max(byte_pairs, key=byte_pairs.get)\n","            # Ends the loop if the most frequent byte pair is rarer than allowed\n","            if byte_pairs[most_frequent] <= self.min_freq:\n","                break\n","            \n","            # Adds the most frequent byte pair to the encoding\n","            self.encoding[most_frequent] = chr(unused_byte)\n","            self.vocab.add(chr(unused_byte))\n","            # Applies the encoding to the corpus\n","            for word in corpus.keys():\n","                corpus[word.replace(most_frequent, chr(unused_byte))] = corpus.pop(word)\n","            # Increment the ord of the unused byte\n","            unused_byte += 1\n","        \n","        # Generate the decoding mapping from the encoding mapping\n","        self.decoding = dict((v,k) for k,v in reversed(list(self.encoding.items())))\n","        print(\"Vocab size: \", len(self.vocab))\n","    \n","    # Tokenize a single string of text\n","    def tokenize(self, txt):\n","        result = txt.replace('\\n', ' ')\n","        for key in self.encoding.keys():\n","            result = result.replace(key, self.encoding[key])\n","        \n","        return result\n","    \n","    # Add a tokenized row to an existing pandas df\n","    def tokenize_all(self, df, text_column='Text'):\n","        df['CustomTokenizer'] = df[text_column].apply(lambda row: self.tokenize(row))\n","    \n","    # Decode a single tokenized string (bars=False if you only want the raw decoded text)\n","    def decode(self, tokenized, bars=True):\n","        if bars:\n","            txt = tokenized.replace('', '|')\n","        for key in self.decoding.keys():\n","            txt = txt.replace(key, self.decoding[key])\n","        return txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101724,"status":"ok","timestamp":1669416125573,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"},"user_tz":300},"id":"c5aZiXVKfJYl","outputId":"8b9441a1-9bc2-4e84-a8b7-f6d8ab6e44f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus size:  36325\n","Vocab size:  1066\n"]}],"source":["custom_tokenizer = Tokenizer()\n","custom_tokenizer.learn(df_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6008,"status":"ok","timestamp":1669416146723,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"},"user_tz":300},"id":"7fzWKRHzdJLm","outputId":"f4a130eb-0e73-4480-d732-0baf8857c3e1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text  IsSpam  \\\n","0  subject: template for pricing the right of fir...     0.0   \n","1  subject: new resume\\ndear vince ,\\ni am so gra...     0.0   \n","2  subject: easily lose weight / build muscle / r...     1.0   \n","3  subject: re : university of texas conference o...     0.0   \n","4  subject: re : replied resume\\nvince / sally\\ni...     0.0   \n","\n","                                    DefaultTokenizer  \\\n","0  [subject, template, for, pricing, the, right, ...   \n","1  [subject, new, resume, dear, vince, ,, i, am, ...   \n","2  [subject, easily, lose, weight, /, build, musc...   \n","3  [subject, re, university, of, texas, conferenc...   \n","4  [subject, re, replied, resume, vince, /, sally...   \n","\n","                                     CustomTokenizer  \n","0  ƈ ŀmƥŐ Ğ ħěƪ Ċ Ѕ ę ͹ ăfńď ĸǨȏ Ė ĤǏ , i Ŭ ̰ ƾ a...  \n","1  ƈ Ǘ ϋ ο vłĢ , i ģ Ɔ ųŐʖ Ğ Ō ȬĞȕ . i ăȌ űǺƧŐ Ĝ ...  \n","2  ƈ eĒĝy ĬĨ ĭȗ / ˖ĝd mńcĘ / ăŁĨ Ņƪ ! 2ǻ31 Ē Ĩć Ă...  \n","3  ƈ ă : Ͷ ę ŀxĒ ̡ Ă ɂ fłǡ , ƇȫҜ ǟ vłĢ , i ģ ͮțƪ ...  \n","4  ƈ ă : ăpƅđ ϋ vłĢ / sȌ ē űƠĎs Ř Ċ Şpƅđ Ш Ă ŉ Ɓ ...  "],"text/html":["\n","  <div id=\"df-e242a68e-ff94-46a6-a5a2-377b90aec053\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>IsSpam</th>\n","      <th>DefaultTokenizer</th>\n","      <th>CustomTokenizer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>subject: template for pricing the right of fir...</td>\n","      <td>0.0</td>\n","      <td>[subject, template, for, pricing, the, right, ...</td>\n","      <td>ƈ ŀmƥŐ Ğ ħěƪ Ċ Ѕ ę ͹ ăfńď ĸǨȏ Ė ĤǏ , i Ŭ ̰ ƾ a...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>subject: new resume\\ndear vince ,\\ni am so gra...</td>\n","      <td>0.0</td>\n","      <td>[subject, new, resume, dear, vince, ,, i, am, ...</td>\n","      <td>ƈ Ǘ ϋ ο vłĢ , i ģ Ɔ ųŐʖ Ğ Ō ȬĞȕ . i ăȌ űǺƧŐ Ĝ ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>subject: easily lose weight / build muscle / r...</td>\n","      <td>1.0</td>\n","      <td>[subject, easily, lose, weight, /, build, musc...</td>\n","      <td>ƈ eĒĝy ĬĨ ĭȗ / ˖ĝd mńcĘ / ăŁĨ Ņƪ ! 2ǻ31 Ē Ĩć Ă...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>subject: re : university of texas conference o...</td>\n","      <td>0.0</td>\n","      <td>[subject, re, university, of, texas, conferenc...</td>\n","      <td>ƈ ă : Ͷ ę ŀxĒ ̡ Ă ɂ fłǡ , ƇȫҜ ǟ vłĢ , i ģ ͮțƪ ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>subject: re : replied resume\\nvince / sally\\ni...</td>\n","      <td>0.0</td>\n","      <td>[subject, re, replied, resume, vince, /, sally...</td>\n","      <td>ƈ ă : ăpƅđ ϋ vłĢ / sȌ ē űƠĎs Ř Ċ Şpƅđ Ш Ă ŉ Ɓ ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e242a68e-ff94-46a6-a5a2-377b90aec053')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e242a68e-ff94-46a6-a5a2-377b90aec053 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e242a68e-ff94-46a6-a5a2-377b90aec053');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["df_train['DefaultTokenizer'] = df_train['Text'].apply(lambda text: tokenizer(text))\n","df_test['DefaultTokenizer'] = df_test['Text'].apply(lambda text: tokenizer(text))\n","custom_tokenizer.tokenize_all(df_train)\n","custom_tokenizer.tokenize_all(df_test)\n","df_train.head()"]},{"cell_type":"markdown","metadata":{"id":"21NyIJ82sizO"},"source":["Visualization for the tokenizer's results + sanity check"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1669416175858,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"},"user_tz":300},"id":"K9dHEt8JyfqC","outputId":"9155c233-02d6-41c8-bf7c-c505795ee49e"},"outputs":[{"output_type":"stream","name":"stdout","text":["subject: wallstreet pulse\n","good day to all broker ' s , day trader ' s and investor ' s world s . tock report\n","has become famous with some great stoc ? k picks in the otc , small cap\n","market ' s ! ! ! ! ! ! ! ! ! ! here at world stoc ? k report we work on what we here\n","from the street . rumor ' s circulating and keeping the focus on the company ' s\n","news . we pick our companies based on there growth potential . we focus on\n","stoc ? ks that have great potential to move up in price ! ! ! while giving\n","you liquitity .\n","our latest pick is cdgt .\n","sy , mbol : cdgt\n","current price : $ 3 . 90\n","short term 7 day projection : $ 8 - 9\n","we give it to you again as a gift . this company is doing incredible things .\n","thay have cash and have made great strategic aquisitions .\n","current price $ 3 . 85 to $ 4 . 00 . word on the sreet is strong buy .\n","this company has dropped big new ' s in the past .\n","who ' s to say they don ' t have another big one .\n","* * * * * * * * * * * * * press release * * * * * * * * * * * * * * * * press release * * * * * * * * * * * * * * * * * *\n","press release source : china digital media corporation\n","china digital media corporation announces an investment in second television\n","drama - ' xiguan affairs ' hong kong , june 29 / xinhua - prnewswire / - -\n","china digital media corporation ( ' ' digimedia ' ' ) ( otc : cdgt - news ;\n","otc bulletin board : cdgt - news ) with its subsidiaries ( together the ' ' group ' ' )\n","announced today the group is committed to invest rmb 4 , 680 , 000 for a minority\n","interests in a television drama , ' ' xiguan affairs ' ' , in the peoples republic of\n","china with guangdong runshi movie & music production co . , ltd . ( ' ' runshi ' ' )\n","through the group ' s affiliated partner - - guangdong huaguang digimedia culture\n","development limited ( ' ' huaguang ' ' ) .\n","advertisement\n","xiguan affairs is a 36 - episode classic television drama and which is\n","filmed in guangdong province . the drama is in its post - production stage and\n","scheduled for a television debut in the second half of 2005 . the company has\n","reached sales agreements with more than half of provincial television\n","stations which cover at least half of the 1 . 14 billion tv viewers in china .\n","the company expects the drama will generate profits in 2005 .\n","this is the second project to partner with huaguang and runshi and it has\n","already produced an encouraging result that the response from the market is\n","exciting .\n","remember the gains from our recent st ? rong bu ? y recommendation ? s . . .\n","disclaimer :\n","information within this email contains \" forwardlooking statements \" within\n","the meaning of section 27 aof the securities act of 1933 and section 21 b of\n","thesecurities exchange act of 1934 . any statements that express or involve\n","discussions with respect to predictions , expectations , beliefs ,\n","plans , projections , objectives , goals , assumptions or future events or\n","performance are not statements of historical fact and may be \" forward\n","looking statements . \" forwardlooking statements are based on\n","expectations , estimates and projections at the time the statements are made\n","that involve a number of risks and uncertainties which could cause actual\n","results or events to differ materially from those presently anticipated .\n","forward looking statements in this action may be identified through the use\n","of words such as \" projects \" , \" foresee \" , \" expects \" , \" will , \" \" anticipates , \"\n","\" estimates , \" \" believes , \" understands \" or that by statements indicating\n","certain actions \" may , \" \" could , \" or \" might \" occur . risk factors include\n","general economic and business conditions , the ability to acquire and develop\n","specific projects , the ability to fund operations and changes in consumer\n","and business consumption habits and other factors overwhich the company has\n","little or no control . the publisher of this newsletter does not represent\n","that the information contained in this message states all material facts or\n","does not omit a material fact necessary to make the statements therein not\n","misleading . all information provided within this email pertaining to\n","investing , stoc ? ks , securities must be understood as information provided and\n","not investment advice . the publisher of this newsletter advises all readers\n","and subscribers to seek advice from a registered professional securities\n","representative before deciding to trade in stoc ? ks featured within this\n","email . none of the material within this report shall be construed as any\n","kind of investment advice or solicitation . many of these companies are on\n","the verge of bankruptcy . you can lose all your money by investing in this\n","stoc ? k . we urge you to read the company ' s sec filings now , before you invest .\n","the publisher of this newsletter is not a registered invstment advisor .\n","subscribers should not view information herein as legal , tax , accounting or\n","investment advice . in compliance with the securitiesact of 1933 , section\n","17 ( b ) , the publisher of this newsletter is contracted to receive six hundred\n","thousand free trading shares from a third party , not an officer , director or\n","affiliate shareholder for the circulation of this report . be aware of an\n","inherent conflict of interest resulting from such compensation due to the\n","fact that this is a paid advertisement and is not without bias . the party\n","that paid us has a position in the stoc ? k they will sell at anytime without\n","notice . this could have a negative impact on the price of the stoc ? k , causing\n","you to lose money . all factual information in this report was gathered from\n","public sources , including but not limited to sec filings , company websites\n","and company press releases . the publisher of this newsletter believes this\n","informationto be eliable but can make no guarantee as to its accuracy or\n","completeness . use of the material within this email constitutes your\n","acceptance of these terms .\n","spam\n","ƈ wūĚăį pŸĨ ̟ Ɖ ċ ū Ήką ' s , Ɖ ʽą ' s Ė ѧŤĉ ' s ѣ s . ċț ˎ ǯ Ī˯ fģˌ Ŋ ȟ Τ ̶c ? k pȄs ł Ċ ͈c , smū ̥ ǫ ' s ! ! ! ! ! ! ! ! ! ! Ǹ Ĉ ѣ ̶c ? k ˎ ĭ ƽ Ă ɘ ĭ Ǹ Ź Ċ Ěăį . rǧĉ ' s cŨcŸĈƪ Ė ŧͰƪ Ċ ǲȈ Ă Ċ ɬ ' s Ϻ . ĭ pȄ ŵ ƲĄƮ ф Ă Ɋ ųͪā ŠϦȾ . ĭ ǲȈ Ă ̶c ? ks Ř Ŭ Τ ŠϦȾ ċ Ҋ ƾ ł ˧ ! ! ! Ŧˑ ҉ƪ Ĝ ƅŲēž . ŵ яŤ pȄ Č cdgt . ɹ , ЃŃ : cdgt ̵ ˧ : $ 3 . 90 ĸĉt п 7 Ɖ ʢĕ : $ 8 - 9 ĭ ϭ ē ċ Ĝ Ņał Ē a gŖt . ŉ ɬ Č Žƪ ł̖̱ āƪs . āĹ Ŭ cϯ Ė Ŭ ѵ Τ ǖŐgě aŲČēƢ . ̵ ˧ $ 3 . 85 ċ $ 4 . Ħ . ƒd Ă Ċ săį Č Ěıg ˖y . ŉ ɬ ǯ ɷřpđ bũ Ǘ ' s ł Ċ pǭ . ʹ ' s ċ sĹ ɿ ɠ ' t Ŭ ĄȰ bũ Ɓ . * * * * * * * * * * * * * Ң ăĘŷ * * * * * * * * * * * * * * * * Ң ăĘŷ * * * * * * * * * * * * * * * * * * Ң ăĘŷ sŵĢ : Ĥła dũēď ̪Ƀ қĮ Ĥła dũēď ̪Ƀ қĮ ΚƸ̩ Ą ѧŤņ ł Ĩķd ŀĘȆĕ ɷģa - ' xũuĄ ȓɁŨs ' hĂg kĂg , jĿe ͍ / xłhua - ħϺľă / - - Ĥła dũēď ̪Ƀ қĮ ( ' ' dũŞđɃ ' ' ) ( ͈c : cdgt - Ϻ ; ͈c bŸǵł ƻť : cdgt - Ϻ ) Ŋ ɩ ѲŒiĎƮ ( ċƬƙ Ċ ' ' ȋ ' ' ) ΚƸђ ϊ Ċ ȋ Č ǓēϞ ċ ѧŤ rЃ 4 , 680 , ˴ Ğ a młĉž łŀȹs ł a ŀĘȆĕ ɷģa , ' ' xũuĄ ȓɁŨs ' ' , ł Ċ ͡Ф ăϘě ę Ĥła Ŋ ˚ʬɠg rĿĸi ŢǮ & mńě ˶ĕ Ʃ . , ltd . ( ' ' rĿĸi ' ' ) Ζ Ċ ȋ ' s ȓfĝiȎ ǣʂ - - ˚ʬɠg huŅuʬ dũŞđɃ cŸtǰ ̀ lŞτ ( ' ' huŅuʬ ' ' ) . ĴŁt̚ņ xũuĄ ȓɁŨs Č a 36 - ͰČoĩ ƺȡě ŀĘȆĕ ɷģa Ė ɪ Č fĝ̪ ł ˚ʬɠg їłĢ . Ċ ɷģa Č ł ɩ ŠĚ - ˶ĕ Ěƌ Ė ɆđŸđ Ğ a ŀĘȆĕ ĩȭ ł Ċ Ĩķd hďf ę ş5 . Ċ ɬ ǯ ăɝđ Ќč Ҟȣ Ŋ ȩ ΁ hďf ę їłɺ ŀĘȆĕ Ěǀ ɪ ƩŁ Ĉ Ęǭ hďf ę Ċ 1 . ̊ bЩ tv ǳż ł Ĥła . Ċ ɬ ˅ğs Ċ ɷģa š ΑŐ ʭɩ ł ş5 . ŉ Č Ċ Ĩķd ʢ ċ ǣʂ Ŋ huŅuʬ Ė rĿĸi Ė ē ǯ ďЇ ʛђ Ą ćΞŅƪ Ѫt Ř Ċ ˝Ĩ Ź Ċ ǫ Č Ŵcēƪ . ăĲʰ Ċ gałs Ź ŵ ăɕ Ě ? ıg ˖ ? y ăǓƄĮ ? s . . . ǤƺaŞą : łưĮ Ŋł ŉ ȶ ɚłs \" ǜȸƪ ̂ȣ \" Ŋł Ċ ĲĄƪ ę sğĕ ΅ aę Ċ Мʫ ƫ ę ɀ33 Ė sğĕ Ѻ b ę ʳǦʫ ŴҐ ƫ ę ɀ34 . Ż ̂ȣ Ř ŴҢ ĉ łШĥ ˤƢ Ŋ śpğ ċ pǁiĐƢ , ˅ğǀ , ҃ŭfs , ƥȞ , ʢƢ , ҝļΆ , Ɨв , ĒˆʺƢ ĉ ѩ ς͔ ĉ ƶĞƘĢ ő Ƃ ̂ȣ ę hƣĉɧ Ν Ė ǹ Ī \" ǜ ȸƪ ̂ȣ . \" ǜȸƪ ̂ȣ ő ф Ă ˅ğǀ , ŤŞ˞ Ė ʢƢ Ĉ Ċ Ǭ Ċ ̂ȣ ő ѵ Ř łШĥ a Ο ę Ȗs Ė Ŀ̐ŮłtƮ ɪ ʷ Є ƫ̠ Ѫȕ ĉ ς͔ ċ Έͣ ͭąiȌ Ź ѢĨ ɑĵ ƀěǈȎ . ǜ ȸƪ ̂ȣ ł ŉ ƫĕ ǹ Ī ˃ŖϿ Ζ Ċ ʲ ę ƒΙ Ђ Ē \" ʢs \" , \" ʩʊ \" , \" ˅ğs \" , \" š , \" \" ƀěǈ˞ , \" \" ŤŞ˞ , \" \" ҃ŭИ , \" ˷̮s \" ĉ Ř ƃ ̂ȣ łděĈƪ ̐Ůł ƫƢ \" ǹ , \" \" ʷ , \" ĉ \" mȗ \" oƟŎ . Ȗ Νˮ łƺ҄ Αď eķėě Ė Țłŗ ķdēƢ , Ċ ѫ ċ ŝκă Ė ɗ ȿcͅ ʢs , Ċ ѫ ċ Ηd ΍ǀ Ė Ѩč ł ķˆą Ė Țłŗ ķˆʺĕ ōbɩ Ė Ȱ Νˮ ɵɪ Ċ ɬ ǯ lētĘ ĉ ĳ ˊŃ . Ċ Ϙʧą ę ŉ ϺǵŇ ц Ƃ ăɑ Ř Ċ łưĮ ɚłđ ł ŉ ɰ Ě˞ ū ͭąȾ Νs ĉ ц Ƃ ėē a ͭąȾ Ν œȴȷ ċ ʼ Ċ ̂ȣ Ɋł Ƃ mČҡƪ . ū łưĮ ҏđ Ŋł ŉ ȶ ƶŮłƪ ċ ѧŤƪ , ̶c ? ks , Мʫ mȍ Ī ĿdżċȠ Ē łưĮ ҏđ Ė Ƃ ѧŤņ іƔ . Ċ Ϙʧą ę ŉ ϺǵŇ ĴȆč ū ˵ż Ė ѲȵƵż ċ ĨȊ іƔ Ź a ǇČŀǁ θĕď Мʫ ăɑʿ Ц ΫŒƪ ċ ̭ĩ ł ̶c ? ks ƇĈuǁ Ŋł ŉ ȶ . nƁ ę Ċ ͭąȾ Ŋł ŉ ˎ ͞ Ī ķ͟đ Ē Ż kłd ę ѧŤņ іƔ ĉ ЮěēĮ . γ ę ʳ ƲĄƮ ő Ă Ċ ŁƬ ę Ϩrƾtϝ . Ĝ ƞ ĬĨ ū Ō ξ ƃ ѧŤƪ ł ŉ ̶c ? k . ĭ ŎƬ Ĝ ċ ˵ Ċ ɬ ' s Ĩc fĝƪs ƭ , Ц Ĝ ѧŤ . Ċ Ϙʧą ę ŉ ϺǵŇ Č Ƃ a ǇČŀǁ ѧĚņ ĴȆĉ . ѲȵƵż ˂ Ƃ ǳ łưĮ Ǹł Ē Ęgď , Ůx , ќƪ ĉ ѧŤņ іƔ . ł Ʋƅǡ Ŋ Ċ Мʫƫ ę ɀ33 , sğĕ ͆ ( b ) , Ċ Ϙʧą ę ŉ ϺǵŇ Č Йđ ċ Ҡ six hĿdǁ āˌĖ ˿ ʽƪ ĸős Ź a āŨd ǣy , Ƃ Ą Ǚěą , ҈ ĉ ȓfĝш ĸőνǆ Ğ Ċ cŨcŸĮ ę ŉ ˎ . Ī Ȣő ę Ą łŏ˽ ϡƅĐ ę łŀȹ Ѫtƪ Ź Ђ Ʋ̒Į ƴe ċ Ċ Ν Ř ŉ Č a ˇŒ ĴŁt̚ņ Ė Č Ƃ ŊƏ biĒ . Ċ ǣy Ř ˇŒ ń ǯ a г ł Ċ ̶c ? k ɿ š ĨƯ Ĉ ŻǬ ŊƏ ƂƔ . ŉ ʷ Ŭ a œgʿ Şpƫ Ă Ċ ˧ ę Ċ ̶c ? k , cańƪ Ĝ ċ ĬĨ ξ . ū Ν̠ łưĮ ł ŉ ˎ Ȓ gaĊǁ Ź Ϙě sŵ̩ , łƺȇƪ ȭ Ƃ lŞτ ċ Ĩc fĝƪs , ɬ ʑǌč Ė ɬ Ң ăĘĒč . Ċ Ϙʧą ę ŉ ϺǵŇ ҃ŭИ ŉ łưĮċ Ī eƅǛ ȭ ƞ ʼ ĳ ˚ĎĄŀe Ē ċ ɩ ŝǦŝy ĉ ϣtćŗ . ʲ ę Ċ ͭąȾ Ŋł ŉ ȶ ķĚēŶč Ō ŝĢʺǡ ę ʳ Ň˼ .\n","|subject:| |w|all|st|re|et| |p|ul|se| |good| |day| |to| |all| |bro|k|er| |'| |s| |,| |day| |trad|er| |'| |s| |and| |inv|est|or| |'| |s| |world| |s| |.| |to|ck| |report| |has| |be|come| |f|am|ous| |with| |some| |great| |sto|c| |?| |k| |p|ick|s| |in| |the| |ot|c| |,| |s|m|all| |cap| |market| |'| |s| |!| |!| |!| |!| |!| |!| |!| |!| |!| |!| |here| |at| |world| |sto|c| |?| |k| |report| |we| |work| |on| |what| |we| |here| |from| |the| |st|re|et| |.| |r|um|or| |'| |s| |c|ir|c|ul|at|ing| |and| |ke|ep|ing| |the| |fo|cus| |on| |the| |company| |'| |s| |news| |.| |we| |p|ick| |our| |comp|an|ies| |based| |on| |there| |gr|ow|th| |po|tent|ial| |.| |we| |fo|cus| |on| |sto|c| |?| |k|s| |that| |have| |great| |po|tent|ial| |to| |move| |up| |in| |price| |!| |!| |!| |wh|ile| |giv|ing| |you| |li|qu|it|ity| |.| |our| |lat|est| |p|ick| |is| |c|d|g|t| |.| |sy| |,| |mb|ol| |:| |c|d|g|t| |current| |price| |:| |$| |3| |.| |9|0| |sh|or|t| |term| |7| |day| |project|ion| |:| |$| |8| |-| |9| |we| |give| |it| |to| |you| |ag|a|in| |as| |a| |g|if|t| |.| |this| |company| |is| |do|ing| |in|cred|ible| |th|ing|s| |.| |th|ay| |have| |c|ash| |and| |have| |made| |great| |str|ate|g|ic| |a|qu|is|it|ions| |.| |current| |price| |$| |3| |.| |8|5| |to| |$| |4| |.| |00| |.| |wor|d| |on| |the| |s|re|et| |is| |st|ron|g| |bu|y| |.| |this| |company| |has| |dr|op|p|ed| |b|ig| |new| |'| |s| |in| |the| |p|ast| |.| |who| |'| |s| |to| |s|ay| |they| |don| |'| |t| |have| |an|other| |b|ig| |one| |.| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |press| |re|le|ase| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |press| |re|le|ase| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |*| |press| |re|le|ase| |s|our|ce| |:| |ch|in|a| |d|ig|it|al| |med|ia| |corpor|ation| |ch|in|a| |d|ig|it|al| |med|ia| |corpor|ation| |ann|oun|ces| |an| |inv|est|ment| |in| |se|con|d| |te|le|vis|ion| |dr|am|a| |-| |'| |x|ig|u|an| |af|fa|ir|s| |'| |h|on|g| |k|on|g| |,| |j|un|e| |29| |/| |x|in|h|u|a| |-| |pr|news|wi|re| |/| |-| |-| |ch|in|a| |d|ig|it|al| |med|ia| |corpor|ation| |(| |'| |'| |d|ig|im|ed|ia| |'| |'| |)| |(| |ot|c| |:| |c|d|g|t| |-| |news| |;| |ot|c| |b|ul|let|in| |bo|ard| |:| |c|d|g|t| |-| |news| |)| |with| |its| |subs|id|i|ar|ies| |(| |to|ge|ther| |the| |'| |'| |group| |'| |'| |)| |ann|oun|ced| |today| |the| |group| |is| |comm|it|ted| |to| |inv|est| |r|mb| |4| |,| |6|8|0| |,| |000| |for| |a| |m|in|or|ity| |in|te|rest|s| |in| |a| |te|le|vis|ion| |dr|am|a| |,| |'| |'| |x|ig|u|an| |af|fa|ir|s| |'| |'| |,| |in| |the| |peop|les| |re|publ|ic| |of| |ch|in|a| |with| |gu|ang|don|g| |r|un|sh|i| |mo|vie| |&| |m|us|ic| |product|ion| |co| |.| |,| |l|t|d| |.| |(| |'| |'| |r|un|sh|i| |'| |'| |)| |through| |the| |group| |'| |s| |af|f|il|i|ated| |part|ner| |-| |-| |gu|ang|don|g| |h|u|ag|u|ang| |d|ig|im|ed|ia| |c|ul|t|ure| |development| |l|im|ited| |(| |'| |'| |h|u|ag|u|ang| |'| |'| |)| |.| |ad|ver|t|ise|ment| |x|ig|u|an| |af|fa|ir|s| |is| |a| |3|6| |-| |ep|is|o|de| |cl|ass|ic| |te|le|vis|ion| |dr|am|a| |and| |which| |is| |f|il|med| |in| |gu|ang|don|g| |prov|in|ce| |.| |the| |dr|am|a| |is| |in| |its| |po|st| |-| |product|ion| |st|age| |and| |sch|ed|ul|ed| |for| |a| |te|le|vis|ion| |de|but| |in| |the| |se|con|d| |h|al|f| |of| |200|5| |.| |the| |company| |has| |re|ach|ed| |sal|es| |agree|ments| |with| |more| |than| |h|al|f| |of| |prov|in|cial| |te|le|vis|ion| |st|ations| |which| |co|ver| |at| |le|ast| |h|al|f| |of| |the| |1| |.| |14| |b|illion| |t|v| |view|ers| |in| |ch|in|a| |.| |the| |company| |exp|ect|s| |the| |dr|am|a| |will| |gener|ate| |prof|its| |in| |200|5| |.| |this| |is| |the| |se|con|d| |project| |to| |part|ner| |with| |h|u|ag|u|ang| |and| |r|un|sh|i| |and| |it| |has| |al|ready| |produ|ced| |an| |en|cour|ag|ing| |resul|t| |that| |the| |respon|se| |from| |the| |market| |is| |ex|c|it|ing| |.| |re|me|mber| |the| |g|a|in|s| |from| |our| |re|cent| |st| |?| |ron|g| |bu| |?| |y| |re|comm|end|ation| |?| |s| |.| |.| |.| |dis|cl|a|im|er| |:| |in|form|ation| |with|in| |this| |email| |conta|in|s| |\"| |forward|look|ing| |state|ments| |\"| |with|in| |the| |me|an|ing| |of| |s|ect|ion| |27| |a|of| |the| |secur|ities| |act| |of| |19|3|3| |and| |s|ect|ion| |21| |b| |of| |these|cur|ities| |ex|change| |act| |of| |19|3|4| |.| |any| |state|ments| |that| |ex|press| |or| |in|vol|ve| |discuss|ions| |with| |res|p|ect| |to| |p|red|i|ct|ions| |,| |exp|ect|ations| |,| |bel|ie|f|s| |,| |pl|ans| |,| |project|ions| |,| |ob|ject|ives| |,| |go|als| |,| |as|sum|pt|ions| |or| |future| |ev|ents| |or| |per|for|man|ce| |are| |not| |state|ments| |of| |h|ist|or|ical| |fact| |and| |may| |be| |\"| |forward| |look|ing| |state|ments| |.| |\"| |forward|look|ing| |state|ments| |are| |based| |on| |exp|ect|ations| |,| |est|im|ates| |and| |project|ions| |at| |the| |time| |the| |state|ments| |are| |made| |that| |in|vol|ve| |a| |number| |of| |risk|s| |and| |un|cer|ta|in|t|ies| |which| |could| |cause| |act|ual| |resul|ts| |or| |ev|ents| |to| |dif|fer| |mat|er|i|ally| |from| |tho|se| |present|ly| |ant|ic|ip|ated| |.| |forward| |look|ing| |state|ments| |in| |this| |act|ion| |may| |be| |ident|if|ied| |through| |the| |use| |of| |wor|ds| |such| |as| |\"| |project|s| |\"| |,| |\"| |fore|see| |\"| |,| |\"| |exp|ect|s| |\"| |,| |\"| |will| |,| |\"| |\"| |ant|ic|ip|ates| |,| |\"| |\"| |est|im|ates| |,| |\"| |\"| |bel|ie|ves| |,| |\"| |under|stand|s| |\"| |or| |that| |by| |state|ments| |in|d|ic|at|ing| |cer|ta|in| |act|ions| |\"| |may| |,| |\"| |\"| |could| |,| |\"| |or| |\"| |m|ight| |\"| |o|cc|ur| |.| |risk| |fact|ors| |in|cl|ude| |gener|al| |e|con|om|ic| |and| |bus|in|ess| |con|d|it|ions| |,| |the| |ability| |to| |ac|qui|re| |and| |develop| |spe|c|ific| |project|s| |,| |the| |ability| |to| |fun|d| |oper|ations| |and| |chang|es| |in| |con|sum|er| |and| |bus|in|ess| |con|sum|pt|ion| |ha|b|its| |and| |other| |fact|ors| |over|which| |the| |company| |has| |l|it|t|le| |or| |no| |contr|ol| |.| |the| |publ|ish|er| |of| |this| |news|let|ter| |does| |not| |re|present| |that| |the| |in|form|ation| |conta|in|ed| |in| |this| |message| |st|ates| |all| |mat|er|ial| |fact|s| |or| |does| |not| |om|it| |a| |mat|er|ial| |fact| |ne|cess|ary| |to| |make| |the| |state|ments| |there|in| |not| |m|is|lead|ing| |.| |all| |in|form|ation| |provid|ed| |with|in| |this| |email| |per|ta|in|ing| |to| |inv|est|ing| |,| |sto|c| |?| |k|s| |,| |secur|ities| |m|ust| |be| |un|d|ers|to|od| |as| |in|form|ation| |provid|ed| |and| |not| |inv|est|ment| |adv|ice| |.| |the| |publ|ish|er| |of| |this| |news|let|ter| |ad|vis|es| |all| |read|ers| |and| |subs|cr|ib|ers| |to| |se|ek| |adv|ice| |from| |a| |reg|is|te|red| |profess|ion|al| |secur|ities| |re|present|ative| |before| |dec|id|ing| |to| |tra|de| |in| |sto|c| |?| |k|s| |fe|at|u|red| |with|in| |this| |email| |.| |n|one| |of| |the| |mat|er|ial| |with|in| |this| |report| |shall| |be| |con|stru|ed| |as| |any| |k|in|d| |of| |inv|est|ment| |adv|ice| |or| |sol|ic|it|ation| |.| |many| |of| |these| |comp|an|ies| |are| |on| |the| |ver|ge| |of| |bank|r|up|t|cy| |.| |you| |can| |lo|se| |all| |your| |money| |by| |inv|est|ing| |in| |this| |sto|c| |?| |k| |.| |we| |ur|ge| |you| |to| |read| |the| |company| |'| |s| |se|c| |f|il|ing|s| |now| |,| |before| |you| |inv|est| |.| |the| |publ|ish|er| |of| |this| |news|let|ter| |is| |not| |a| |reg|is|te|red| |inv|st|ment| |ad|vis|or| |.| |subs|cr|ib|ers| |should| |not| |view| |in|form|ation| |here|in| |as| |le|g|al| |,| |ta|x| |,| |account|ing| |or| |inv|est|ment| |adv|ice| |.| |in| |comp|li|ance| |with| |the| |secur|ities|act| |of| |19|3|3| |,| |s|ect|ion| |17| |(| |b| |)| |,| |the| |publ|ish|er| |of| |this| |news|let|ter| |is| |contract|ed| |to| |receive| |s|i|x| |h|un|d|red| |th|ous|and| |free| |trad|ing| |sh|are|s| |from| |a| |th|ir|d| |part|y| |,| |not| |an| |off|ic|er| |,| |director| |or| |af|f|il|iate| |sh|are|hol|der| |for| |the| |c|ir|c|ul|ation| |of| |this| |report| |.| |be| |aw|are| |of| |an| |in|he|rent| |conf|li|ct| |of| |in|te|rest| |resul|t|ing| |from| |such| |comp|ens|ation| |du|e| |to| |the| |fact| |that| |this| |is| |a| |pa|id| |ad|ver|t|ise|ment| |and| |is| |not| |with|out| |b|i|as| |.| |the| |part|y| |that| |pa|id| |us| |has| |a| |position| |in| |the| |sto|c| |?| |k| |they| |will| |se|ll| |at| |any|time| |with|out| |not|ice| |.| |this| |could| |have| |a| |ne|g|ative| |im|p|act| |on| |the| |price| |of| |the| |sto|c| |?| |k| |,| |c|a|us|ing| |you| |to| |lo|se| |money| |.| |all| |fact|ual| |in|form|ation| |in| |this| |report| |was| |g|a|the|red| |from| |publ|ic| |s|our|ces| |,| |in|cl|ud|ing| |but| |not| |l|im|ited| |to| |se|c| |f|il|ing|s| |,| |company| |web|sit|es| |and| |company| |press| |re|le|as|es| |.| |the| |publ|ish|er| |of| |this| |news|let|ter| |bel|ie|ves| |this| |in|form|ation|to| |be| |e|li|able| |but| |can| |make| |no| |gu|ar|an|te|e| |as| |to| |its| |ac|cur|ac|y| |or| |comple|t|en|ess| |.| |use| |of| |the| |mat|er|ial| |with|in| |this| |email| |con|st|it|ut|es| |your| |ac|ce|pt|ance| |of| |these| |ter|ms| |.|\n"]}],"source":["row = 0\n","sanity = df_test['Text'][row]\n","tokenized = custom_tokenizer.tokenize(sanity)\n","print(sanity)\n","print('spam' if df['IsSpam'][row] else 'not spam')\n","print(tokenized)\n","tokenized = tokenized.replace('','|')\n","for key in custom_tokenizer.decoding.keys():\n","    tokenized = tokenized.replace(key, custom_tokenizer.decoding[key])\n","print(tokenized)"]},{"cell_type":"markdown","source":["# Additional Preparation\n","\n","Transforming the pandas dfs into pytorch datasets"],"metadata":{"id":"RJ5QjBbQ4j2k"}},{"cell_type":"code","source":["import torch\n","\n","vocab_list = list(custom_tokenizer.vocab)\n","custom_vocab_dict = {vocab_list[i]: i for i in range(len(vocab_list))}\n","\n","class DataFromDF(torch.utils.data.Dataset):\n","    def __init__(self, dataframe, tokenizer_type, max_tokens=200):\n","        self.y = torch.tensor(dataframe['IsSpam'], dtype=torch.long)\n","        # Using index representations as a middleman for text vectorization\n","        vocab_dict = custom_vocab_dict if tokenizer_type == 'CustomTokenizer' else torch_vocab\n","\n","        self.x = torch.tensor(dataframe[tokenizer_type].apply(\n","            lambda text: [vocab_dict[ch] if ch in vocab_dict else 0 for ch in text]).apply(\n","                lambda tokens: tokens[:max_tokens] if len(tokens) >= max_tokens else tokens+([0]* (max_tokens-len(tokens)))), dtype=torch.int)\n","    \n","    def __len__(self):\n","        return len(self.y)\n","    \n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]"],"metadata":{"id":"NncBqXxK92Sp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["default_train = DataFromDF(df_train, 'DefaultTokenizer')\n","default_test = DataFromDF(df_test, 'DefaultTokenizer')\n","custom_train = DataFromDF(df_train, 'CustomTokenizer')\n","custom_test = DataFromDF(df_test, 'CustomTokenizer')\n","print(default_train.x)\n","print(custom_train.x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceYpGC6OE_pZ","executionInfo":{"status":"ok","timestamp":1669416580238,"user_tz":300,"elapsed":2572,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"7e0309dc-1b09-4dc7-9147-057e0793813d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[   24,  4037,    15,  ...,     0,     0,     0],\n","        [   24,    84,   254,  ...,     0,     0,     0],\n","        [   24,  1814,  1577,  ...,     0,     0,     0],\n","        ...,\n","        [   24,  9563, 31795,  ...,     0,     0,     0],\n","        [   24,  3745,   188,  ...,   511,   125,   199],\n","        [   24,    59,    17,  ...,    35,   579,   112]], dtype=torch.int32)\n","tensor([[ 594,    0,  672,  ...,    0,  390,    0],\n","        [ 594,    0, 1025,  ..., 1020, 1020,  603],\n","        [ 594,    0,    5,  ...,    0,  171,  937],\n","        ...,\n","        [ 594,    0,  901,  ...,  779,  568,    0],\n","        [ 594,    0,  312,  ...,  888,    0,  769],\n","        [ 594,    0,  312,  ...,  551,    5,    6]], dtype=torch.int32)\n"]}]},{"cell_type":"markdown","source":["Data loading"],"metadata":{"id":"6Pd66bE4M1r2"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","# Change here to define a batch size\n","n_batches = 10\n","train_loader_def = DataLoader(default_train, batch_size=n_batches)\n","test_loader_def  = DataLoader(default_test, batch_size=n_batches)\n","train_loader_cus = DataLoader(custom_train, batch_size=n_batches)\n","test_loader_cus  = DataLoader(custom_test, batch_size=n_batches)"],"metadata":{"id":"W5cbOV1fM0i7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for x, y in train_loader_def:\n","    print(x.shape, y.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YdKQT439OdWT","executionInfo":{"status":"ok","timestamp":1669416589971,"user_tz":300,"elapsed":117,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"2103ebe5-0dde-4c7c-fed6-8760bdd4e5f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 200]) torch.Size([10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"ID9MLw29S9dS"},"source":["# Prediction\n","\n","PyTorch-based RNN models"]},{"cell_type":"code","source":["from torch import nn\n","from torch.nn import functional as F\n","\n","embed_len = 50\n","hidden_dim = 50\n","n_layers=1\n","\n","custom_vocab = list(custom_tokenizer.vocab)\n","target_classes = ['ham', 'spam']\n","\n","class RNNClassifier(nn.Module):\n","    def __init__(self, vocab):\n","        super(RNNClassifier, self).__init__()\n","        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n","        self.rnn = nn.RNN(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n","        self.linear = nn.Linear(hidden_dim, len(target_classes))\n","\n","    def forward(self, X_batch):\n","        embeddings = self.embedding_layer(X_batch)\n","        output, hidden = self.rnn(embeddings, torch.randn(n_layers, len(X_batch), hidden_dim))\n","        return self.linear(output[:,-1])"],"metadata":{"id":"s0FtcLIDw1j1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["default_model = RNNClassifier(torch_vocab)\n","\n","default_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHltCR4DyWAd","executionInfo":{"status":"ok","timestamp":1669416779314,"user_tz":300,"elapsed":115,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"f4b3b76a-1b88-4579-d504-fe182266de16"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNClassifier(\n","  (embedding_layer): Embedding(36274, 50)\n","  (rnn): RNN(50, 50, batch_first=True)\n","  (linear): Linear(in_features=50, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["for layer in default_model.children():\n","    print(\"Layer : {}\".format(layer))\n","    print(\"Parameters : \")\n","    for param in layer.parameters():\n","        print(param.shape)\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hnwpS3jz51m","executionInfo":{"status":"ok","timestamp":1669416781091,"user_tz":300,"elapsed":118,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"3450d730-b22f-4e93-d3bb-0eea00c7f90d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer : Embedding(36274, 50)\n","Parameters : \n","torch.Size([36274, 50])\n","\n","Layer : RNN(50, 50, batch_first=True)\n","Parameters : \n","torch.Size([50, 50])\n","torch.Size([50, 50])\n","torch.Size([50])\n","torch.Size([50])\n","\n","Layer : Linear(in_features=50, out_features=2, bias=True)\n","Parameters : \n","torch.Size([2, 50])\n","torch.Size([2])\n","\n"]}]},{"cell_type":"code","source":["custom_model = RNNClassifier(custom_vocab)\n","\n","custom_model"],"metadata":{"id":"0vrDasan3xJA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669416675225,"user_tz":300,"elapsed":111,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"3b656a3c-0401-454e-b734-89740f1868fb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNClassifier(\n","  (embedding_layer): Embedding(1066, 50)\n","  (rnn): RNN(50, 50, batch_first=True)\n","  (linear): Linear(in_features=50, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["for layer in custom_model.children():\n","    print(\"Layer : {}\".format(layer))\n","    print(\"Parameters : \")\n","    for param in layer.parameters():\n","        print(param.shape)\n","    print()"],"metadata":{"id":"proPgNiD365P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669416677100,"user_tz":300,"elapsed":114,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"0e5cc269-9410-4d34-dba4-30e014445385"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer : Embedding(1066, 50)\n","Parameters : \n","torch.Size([1066, 50])\n","\n","Layer : RNN(50, 50, batch_first=True)\n","Parameters : \n","torch.Size([50, 50])\n","torch.Size([50, 50])\n","torch.Size([50])\n","torch.Size([50])\n","\n","Layer : Linear(in_features=50, out_features=2, bias=True)\n","Parameters : \n","torch.Size([2, 50])\n","torch.Size([2])\n","\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","import gc\n","\n","def CalcValLossAndAccuracy(model, loss_fn, val_loader):\n","    with torch.no_grad():\n","        Y_shuffled, Y_preds, losses = [],[],[]\n","        for X, Y in val_loader:\n","            preds = model(X)\n","            loss = loss_fn(preds, Y)\n","            losses.append(loss.item())\n","\n","            Y_shuffled.append(Y)\n","            Y_preds.append(preds.argmax(dim=-1))\n","\n","        Y_shuffled = torch.cat(Y_shuffled)\n","        Y_preds = torch.cat(Y_preds)\n","\n","        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n","        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n","\n","\n","def TrainModel(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n","    for i in range(1, epochs+1):\n","        losses = []\n","        for X, Y in tqdm(train_loader):\n","            Y_preds = model(X)\n","\n","            loss = loss_fn(Y_preds, Y)\n","            losses.append(loss.item())\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n","        CalcValLossAndAccuracy(model, loss_fn, val_loader)"],"metadata":{"id":"POqbe7KG0J-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam\n","\n","epochs = 15\n","learning_rate = 0.001\n","\n","loss_fn = nn.CrossEntropyLoss()\n","default_model = RNNClassifier(torch_vocab)\n","optimizer = Adam(default_model.parameters(), lr=learning_rate)\n","\n","TrainModel(default_model, loss_fn, optimizer, train_loader_def, test_loader_def, epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6PhEYiJEqCD","executionInfo":{"status":"ok","timestamp":1669417150590,"user_tz":300,"elapsed":277314,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"6a8abde5-4f11-4c4f-a1b5-2792f158922e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:17<00:00, 26.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.543\n","Valid Loss : 0.539\n","Valid Acc  : 0.754\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:18<00:00, 25.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.501\n","Valid Loss : 0.525\n","Valid Acc  : 0.753\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:22<00:00, 21.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.458\n","Valid Loss : 0.537\n","Valid Acc  : 0.735\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:19<00:00, 23.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.416\n","Valid Loss : 0.524\n","Valid Acc  : 0.764\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:19<00:00, 24.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.383\n","Valid Loss : 0.523\n","Valid Acc  : 0.767\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:18<00:00, 25.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.373\n","Valid Loss : 0.534\n","Valid Acc  : 0.763\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:18<00:00, 25.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.341\n","Valid Loss : 0.540\n","Valid Acc  : 0.776\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:16<00:00, 27.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.335\n","Valid Loss : 0.542\n","Valid Acc  : 0.776\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:18<00:00, 25.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.317\n","Valid Loss : 0.552\n","Valid Acc  : 0.780\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:17<00:00, 26.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.310\n","Valid Loss : 0.552\n","Valid Acc  : 0.781\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:17<00:00, 27.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.333\n","Valid Loss : 0.594\n","Valid Acc  : 0.747\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:15<00:00, 29.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.319\n","Valid Loss : 0.572\n","Valid Acc  : 0.772\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:16<00:00, 27.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.342\n","Valid Loss : 0.557\n","Valid Acc  : 0.755\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:17<00:00, 27.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.323\n","Valid Loss : 0.559\n","Valid Acc  : 0.769\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:16<00:00, 28.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.310\n","Valid Loss : 0.565\n","Valid Acc  : 0.769\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","def MakePredictions(model, loader):\n","    Y_shuffled, Y_preds = [], []\n","    for X, Y in loader:\n","        preds = model(X)\n","        Y_preds.append(preds)\n","        Y_shuffled.append(Y)\n","    gc.collect()\n","    Y_preds, Y_shuffled = torch.cat(Y_preds), torch.cat(Y_shuffled)\n","\n","    return Y_shuffled.detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).detach().numpy()\n","\n","Y_actual, Y_preds = MakePredictions(default_model, test_loader_def)\n","\n","print(\"---MODEL WITH DEFAULT TOKENIZER---\")\n","print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n","print(\"\\nClassification Report : \")\n","print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n","print(\"\\nConfusion Matrix : \")\n","print(confusion_matrix(Y_actual, Y_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cvrqJbFZkca","executionInfo":{"status":"ok","timestamp":1669417155288,"user_tz":300,"elapsed":1221,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"9d0199fa-653a-4d3a-e5b5-2c931a98c3be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---MODEL WITH DEFAULT TOKENIZER---\n","Test Accuracy : 0.7687713310580204\n","\n","Classification Report : \n","              precision    recall  f1-score   support\n","\n","         ham       0.77      0.97      0.86       857\n","        spam       0.73      0.22      0.34       315\n","\n","    accuracy                           0.77      1172\n","   macro avg       0.75      0.60      0.60      1172\n","weighted avg       0.76      0.77      0.72      1172\n","\n","\n","Confusion Matrix : \n","[[831  26]\n"," [245  70]]\n"]}]},{"cell_type":"code","source":["custom_model = RNNClassifier(custom_vocab)\n","optimizer = Adam(custom_model.parameters(), lr=learning_rate)\n","\n","TrainModel(custom_model, loss_fn, optimizer, train_loader_cus, test_loader_cus, epochs)"],"metadata":{"id":"gqYVtwS14OQB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669417394555,"user_tz":300,"elapsed":133817,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"41c6aeae-787a-4730-b37d-c8f1ebd2073e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 55.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.563\n","Valid Loss : 0.570\n","Valid Acc  : 0.734\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:07<00:00, 59.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.520\n","Valid Loss : 0.551\n","Valid Acc  : 0.737\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 53.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.480\n","Valid Loss : 0.485\n","Valid Acc  : 0.788\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 55.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.440\n","Valid Loss : 0.510\n","Valid Acc  : 0.778\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 57.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.501\n","Valid Loss : 0.534\n","Valid Acc  : 0.759\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 56.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.425\n","Valid Loss : 0.533\n","Valid Acc  : 0.771\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 56.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.391\n","Valid Loss : 0.533\n","Valid Acc  : 0.799\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 53.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.345\n","Valid Loss : 0.493\n","Valid Acc  : 0.798\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:09<00:00, 48.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.316\n","Valid Loss : 0.476\n","Valid Acc  : 0.803\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 56.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.295\n","Valid Loss : 0.476\n","Valid Acc  : 0.824\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 56.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.270\n","Valid Loss : 0.599\n","Valid Acc  : 0.777\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 56.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.296\n","Valid Loss : 0.450\n","Valid Acc  : 0.828\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 53.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.353\n","Valid Loss : 0.492\n","Valid Acc  : 0.816\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 55.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.263\n","Valid Loss : 0.477\n","Valid Acc  : 0.837\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [00:08<00:00, 53.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss : 0.211\n","Valid Loss : 0.476\n","Valid Acc  : 0.832\n"]}]},{"cell_type":"code","source":["Y_actual, Y_preds = MakePredictions(custom_model, test_loader_cus)\n","\n","print(\"---MODEL WITH CUSTOM TOKENIZER---\")\n","print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n","print(\"\\nClassification Report : \")\n","print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n","print(\"\\nConfusion Matrix : \")\n","print(confusion_matrix(Y_actual, Y_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669417399474,"user_tz":300,"elapsed":981,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"74ae5057-c0b3-48d5-c56e-f00849aaf1ea","id":"1W_sioLR4hrt"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---MODEL WITH CUSTOM TOKENIZER---\n","Test Accuracy : 0.8327645051194539\n","\n","Classification Report : \n","              precision    recall  f1-score   support\n","\n","         ham       0.89      0.88      0.88       857\n","        spam       0.68      0.70      0.69       315\n","\n","    accuracy                           0.83      1172\n","   macro avg       0.79      0.79      0.79      1172\n","weighted avg       0.83      0.83      0.83      1172\n","\n","\n","Confusion Matrix : \n","[[754 103]\n"," [ 93 222]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"6v2jS0Cyaepl"},"source":["# Sanity check with the enron1 set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":22402,"status":"ok","timestamp":1669417951326,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"},"user_tz":300},"id":"K7yiECRnYaKB","outputId":"0297a104-16db-4dfa-b4e1-7b298d21ff14"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text  IsSpam\n","0  subject: hpl nom for december 22 , 2000\\n( see...     0.0\n","1  subject: eol application id and password\\ndarr...     0.0\n","2  subject: re : meter 984229 - roos common point...     0.0\n","3  subject: info\\nneh b 27 q 71 tojlmjuob 2 wj jl...     1.0\n","4  subject: brand new teenager peeing\\nyou don ' ...     1.0"],"text/html":["\n","  <div id=\"df-da12b072-8ff8-469a-bd01-7600aa70d681\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>IsSpam</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>subject: hpl nom for december 22 , 2000\\n( see...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>subject: eol application id and password\\ndarr...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>subject: re : meter 984229 - roos common point...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>subject: info\\nneh b 27 q 71 tojlmjuob 2 wj jl...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>subject: brand new teenager peeing\\nyou don ' ...</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da12b072-8ff8-469a-bd01-7600aa70d681')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-da12b072-8ff8-469a-bd01-7600aa70d681 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-da12b072-8ff8-469a-bd01-7600aa70d681');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":48}],"source":["path1 = path.replace('enron2', 'enron1')\n","ham = os.scandir(path1 + 'ham')\n","spam = os.scandir(path1 + 'spam')\n","df1 = pd.DataFrame({'Text': [], 'IsSpam': []})\n","\n","for entry in ham:\n","    file_name = path1 + 'ham/' + entry.name\n","    f = open(file_name, mode='r', encoding='latin1')\n","    txt = f.read().lower()\n","    f.close()\n","\n","    df1 = df1.append({'Text': txt, 'IsSpam': False}, ignore_index=True)\n","\n","for entry in spam:\n","    file_name = path1 + 'spam/' + entry.name\n","    f = open(file_name, mode='r', encoding='latin1')\n","    txt = f.read().lower()\n","    f.close()\n","\n","    df1 = df1.append({'Text': txt, 'IsSpam': True}, ignore_index=True)\n","\n","df1 = df1.sample(frac=1).reset_index(drop=True)\n","df1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4999,"status":"ok","timestamp":1669417960834,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"},"user_tz":300},"id":"VHtuu58neQBg","outputId":"45cc106f-be82-4f40-8c02-70801ff3ef23"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                Text  IsSpam  \\\n","0  subject: hpl nom for december 22 , 2000\\n( see...     0.0   \n","1  subject: eol application id and password\\ndarr...     0.0   \n","2  subject: re : meter 984229 - roos common point...     0.0   \n","3  subject: info\\nneh b 27 q 71 tojlmjuob 2 wj jl...     1.0   \n","4  subject: brand new teenager peeing\\nyou don ' ...     1.0   \n","\n","                                     CustomTokenizer  \\\n","0  ƈ hƥ nė Ğ ĩĢʰ Ж , ơ ( ʊ ΰ fˑ : hƥnl Ж2 . xls )...   \n","1  ƈ eŃ űƥѱ Œ Ė pȡƒd dĎƐ , Ō Œ Ė pȡƒd Ğ eŃ űƥѱ Č ...   \n","2  ƈ ă : Ҩą 9842͍ - ƜЕ ǓĂ Šłt - ̭ĩ zƁ ̸ vǡ : ƶ ŵ ...   \n","3  ƈ łǲ œh b ΅ q 71 ċjlmjuҝ 2 wj jlƜ 87 d 2 452 p...   \n","4  ƈ ȫĖ Ǘ ŀćŅą Ơeƪ Ĝ ɠ ' t Ǫ Ĳ Ź Ĵģ . : ) iyʄubĂĄ...   \n","\n","                                    DefaultTokenizer  \n","0  [subject, hpl, nom, for, december, 22, ,, 2000...  \n","1  [subject, eol, application, id, and, password,...  \n","2  [subject, re, meter, 984229, -, roos, common, ...  \n","3  [subject, info, neh, b, 27, q, 71, tojlmjuob, ...  \n","4  [subject, brand, new, teenager, peeing, you, d...  "],"text/html":["\n","  <div id=\"df-f7cc21c3-412c-4fb8-9bb3-d3e8e3bddb58\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>IsSpam</th>\n","      <th>CustomTokenizer</th>\n","      <th>DefaultTokenizer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>subject: hpl nom for december 22 , 2000\\n( see...</td>\n","      <td>0.0</td>\n","      <td>ƈ hƥ nė Ğ ĩĢʰ Ж , ơ ( ʊ ΰ fˑ : hƥnl Ж2 . xls )...</td>\n","      <td>[subject, hpl, nom, for, december, 22, ,, 2000...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>subject: eol application id and password\\ndarr...</td>\n","      <td>0.0</td>\n","      <td>ƈ eŃ űƥѱ Œ Ė pȡƒd dĎƐ , Ō Œ Ė pȡƒd Ğ eŃ űƥѱ Č ...</td>\n","      <td>[subject, eol, application, id, and, password,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>subject: re : meter 984229 - roos common point...</td>\n","      <td>0.0</td>\n","      <td>ƈ ă : Ҩą 9842͍ - ƜЕ ǓĂ Šłt - ̭ĩ zƁ ̸ vǡ : ƶ ŵ ...</td>\n","      <td>[subject, re, meter, 984229, -, roos, common, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>subject: info\\nneh b 27 q 71 tojlmjuob 2 wj jl...</td>\n","      <td>1.0</td>\n","      <td>ƈ łǲ œh b ΅ q 71 ċjlmjuҝ 2 wj jlƜ 87 d 2 452 p...</td>\n","      <td>[subject, info, neh, b, 27, q, 71, tojlmjuob, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>subject: brand new teenager peeing\\nyou don ' ...</td>\n","      <td>1.0</td>\n","      <td>ƈ ȫĖ Ǘ ŀćŅą Ơeƪ Ĝ ɠ ' t Ǫ Ĳ Ź Ĵģ . : ) iyʄubĂĄ...</td>\n","      <td>[subject, brand, new, teenager, peeing, you, d...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7cc21c3-412c-4fb8-9bb3-d3e8e3bddb58')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f7cc21c3-412c-4fb8-9bb3-d3e8e3bddb58 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f7cc21c3-412c-4fb8-9bb3-d3e8e3bddb58');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}],"source":["custom_tokenizer.tokenize_all(df1)\n","df1['DefaultTokenizer'] = df1['Text'].apply(lambda text: tokenizer(text))\n","\n","enron1_default = DataFromDF(df1, 'DefaultTokenizer')\n","enron1_custom = DataFromDF(df1, 'CustomTokenizer')\n","\n","df1.head()"]},{"cell_type":"code","source":["enron1_loader_def = DataLoader(enron1_default, batch_size=n_batches)\n","enron1_loader_cus  = DataLoader(enron1_custom, batch_size=n_batches)"],"metadata":{"id":"VywFEXiTEwdi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_actual, Y_preds = MakePredictions(default_model, enron1_loader_def)\n","\n","print(\"---MODEL WITH CUSTOM TOKENIZER---\")\n","print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n","print(\"\\nClassification Report : \")\n","print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n","print(\"\\nConfusion Matrix : \")\n","print(confusion_matrix(Y_actual, Y_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKpvJszmDQi9","executionInfo":{"status":"ok","timestamp":1669418196913,"user_tz":300,"elapsed":4422,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"de89649a-5994-48fd-e15c-9ddbb5262e3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---MODEL WITH CUSTOM TOKENIZER---\n","Test Accuracy : 0.715583913379737\n","\n","Classification Report : \n","              precision    recall  f1-score   support\n","\n","         ham       0.72      0.98      0.83      3672\n","        spam       0.59      0.07      0.12      1500\n","\n","    accuracy                           0.72      5172\n","   macro avg       0.65      0.52      0.47      5172\n","weighted avg       0.68      0.72      0.62      5172\n","\n","\n","Confusion Matrix : \n","[[3602   70]\n"," [1401   99]]\n"]}]},{"cell_type":"code","source":["Y_actual, Y_preds = MakePredictions(custom_model, enron1_loader_cus)\n","\n","print(\"---MODEL WITH CUSTOM TOKENIZER---\")\n","print(\"Test Accuracy : {}\".format(accuracy_score(Y_actual, Y_preds)))\n","print(\"\\nClassification Report : \")\n","print(classification_report(Y_actual, Y_preds, target_names=target_classes))\n","print(\"\\nConfusion Matrix : \")\n","print(confusion_matrix(Y_actual, Y_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9G7vKsEDY6A","executionInfo":{"status":"ok","timestamp":1669418220825,"user_tz":300,"elapsed":2858,"user":{"displayName":"Derek Xu","userId":"01833340215514714837"}},"outputId":"d884e515-05f6-4de6-ac91-8cd8b269d743"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---MODEL WITH CUSTOM TOKENIZER---\n","Test Accuracy : 0.7097834493426141\n","\n","Classification Report : \n","              precision    recall  f1-score   support\n","\n","         ham       0.82      0.76      0.79      3672\n","        spam       0.50      0.59      0.54      1500\n","\n","    accuracy                           0.71      5172\n","   macro avg       0.66      0.67      0.66      5172\n","weighted avg       0.73      0.71      0.72      5172\n","\n","\n","Confusion Matrix : \n","[[2785  887]\n"," [ 614  886]]\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkpP3DIe3nSFoC04ZwnXsU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}